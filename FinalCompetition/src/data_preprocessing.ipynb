{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Code to create FAT2019 Preprocessed Mel-spectrogram Dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport math\nimport time\nimport pickle\nimport random\n\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport PIL\nimport IPython\nimport IPython.display\nfrom pathlib import Path\nfrom tqdm import tqdm_notebook\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\nfrom IPython import display as ipd\nfrom mne.time_frequency import psd_multitaper\nimport mne","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA = Path('../input/freesound-audio-tagging-2019')\n#PREPROCESSED = Path('../input/fat2019_prep_mels1')\nPREPROCESSED = Path('work/fat2019_prep_mels1')\nWORK = Path('work')\nPath(PREPROCESSED).mkdir(exist_ok=True, parents=True)\nPath(WORK).mkdir(exist_ok=True, parents=True)\n\nCSV_TRN_CURATED = DATA/'train_curated.csv'\nCSV_TRN_NOISY = DATA/'train_noisy.csv'\nCSV_SUBMISSION = DATA/'sample_submission.csv'\n\nTRN_CURATED = DATA/'train_curated'\nTRN_NOISY = DATA/'train_noisy'\nTEST = DATA/'test'\n\nMELS_TRN_CURATED = PREPROCESSED/'mels_train_curated.pkl'\nMELS_TRN_NOISY = PREPROCESSED/'mels_train_noisy.pkl'\nMELS_TEST = PREPROCESSED/'mels_test.pkl'\n\nMFCC_TRN_CURATED = PREPROCESSED/'mfcc_train_curated.pkl'\nMFCC_TRN_NOISY = PREPROCESSED/'mfcc_train_noisy.pkl'\nMFCC_TEST = PREPROCESSED/'mfcc_test.pkl'\n\nCSV_TRN_NOISY_BEST50S = PREPROCESSED/'trn_noisy_best50s.csv'\nMELS_TRN_NOISY_BEST50S = PREPROCESSED/'mels_trn_noisy_best50s.pkl'\nMFCC_TRN_NOISY_BEST50S = PREPROCESSED/'mfcc_trn_noisy_best50s.pkl'\n\ntrn_curated_df = pd.read_csv(CSV_TRN_CURATED)\ntrn_noisy_df = pd.read_csv(CSV_TRN_NOISY)\ntest_df = pd.read_csv(CSV_SUBMISSION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def audio_analysis(x, draw_plot=True):\n    \n    # Obtain audio data\n    rate, data = wavfile.read(TRN_CURATED/x)\n    data = data.astype(float)\n    data /= data.max()\n    \n    if draw_plot:\n        # Plot\n        plt.figure(figsize=(16,9))\n\n        # Waveform\n        ax = plt.subplot(311)\n#         ax.set_title('{} / {} / {}'.format(x, x.labels, f'Curated={x.curated}'))\n        ax.set_ylabel('Amplitude')    \n        librosa.display.waveplot(data, sr=rate)\n\n        # Spectrogram\n        ax = plt.subplot(312)\n        S = librosa.feature.melspectrogram(data, sr=rate, n_mels=128)\n        log_S = librosa.power_to_db(S, ref=np.max)\n        librosa.display.specshow(log_S, sr=rate, x_axis='time', y_axis='mel')\n        ax.set_title('Mel power spectrogram ')\n        plt.colorbar(format='%+02.0f dB')\n        plt.tight_layout()\n\n        # MFCC coefficient\n        ax = plt.subplot(313)\n        mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n        delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n        librosa.display.specshow(delta2_mfcc)\n        plt.ylabel('MFCC coeffs')\n        plt.xlabel('Time')\n        plt.title('MFCC')\n        plt.colorbar()\n        plt.tight_layout()\n    \n#     return ipd.Audio(filename=TRN_CURATED/x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# audio_analysis('02a5aae7.wav')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rate, data = wavfile.read(TRN_CURATED/'02ddd8da.wav')\ndata = data.astype(float)\n\nif 0 < len(data): \n    data, _ = librosa.effects.trim(data)  # trim, top_db=default(60)\n    \n# print(max(abs(data)), max(data))    \n# print(np.where(abs(data) == max(abs(data))))\n    \nMaxAmp = np.where(abs(data) == max(abs(data)))[0]\nMaxAmp = MaxAmp[np.random.randint(len(MaxAmp))]\nprint(MaxAmp)\n# max_offset = len(data) - conf.samples_long\n# #     print(max_offset)\n# if max(abs(data)) == 0:\n#     data = data[:conf.samples_long]\n# elif (len(data)-index) < index:\n#     offset = (np.random.randint(len(data)-index) if len(data)-index < max_offset else len(data)-index-np.random.randint(max_offset))\n#     data_out = data[(index-(conf.samples_long-offset)):(index+offset)]\n# else:\n#     if index == 0:\n#         offset = 0\n#     elif index < max_offset:\n#         offset = np.random.randint(index)\n#     else:\n#         offset = index-np.random.randint(max_offset)\n#     data_out = data[(index-offset):(index+(conf.samples_long-offset))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndrop_audio_file = ['f76181c4.wav', '77b925c2.wav', '6a1f682a.wav', 'c7db12aa.wav', '7752cc8a.wav','1d44b0bd.wav']\ndrop_index = trn_curated_df.loc[  trn_curated_df['fname'].isin( drop_audio_file ) ].index.values\n\nfor idx in drop_index:\n    trn_curated_df = trn_curated_df.drop(idx)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport random\n\ndef read_audio(conf, pathname, trim_long_data):\n    rate, data = wavfile.read(pathname)\n    data = data.astype(float)\n\n    # workaround: 0 length causes error\n    if 0 < len(data): \n        data, _ = librosa.effects.trim(data)  # trim, top_db=default(60)\n\n    # make it unified length to SAMPLE_DATA_CNT\n    if len(data) > conf.samples_long:             \n        if trim_long_data:\n#             print(pathname)\n            # trim the audio where is nearby the maximun amplitude to a segment of 7 secs\n            MaxAmp = np.where(abs(data) == max(abs(data)))[0]\n            MaxAmp = MaxAmp[np.random.randint(len(MaxAmp))]\n            max_offset = len(data) - conf.samples_long\n            if max(abs(data)) == 0:\n                data = data[:conf.samples_long]\n            elif (len(data)-MaxAmp) < MaxAmp:\n                offset = (np.random.randint(len(data)-MaxAmp) if len(data)-MaxAmp < max_offset else len(data)-MaxAmp-np.random.randint(max_offset))\n                data = data[(MaxAmp-(conf.samples_long-offset)):(MaxAmp+offset)]\n            else:\n                if MaxAmp == 0:\n                    offset = 0\n                elif MaxAmp < max_offset:\n                    offset = np.random.randint(MaxAmp)\n                else:\n                    offset = MaxAmp-np.random.randint(max_offset)\n                data = data[(MaxAmp-offset):(MaxAmp+(conf.samples_long-offset))]\n    else:                                     \n        data = np.tile(data, math.floor(conf.samples/data.shape[0])) \n        if len(data) < conf.samples:\n            max_offset = conf.samples-len(data)\n            offset = np.random.randint(max_offset)\n            data = np.pad(data, (offset, conf.samples-len(data)-offset), \"constant\")\n\n    return data\n\n\ndef audio_to_mels_mfcc(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sampling_rate,\n                                                 n_mels=conf.n_mels,\n#                                                  hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    spectrogram = spectrogram.astype(np.float32)\n    mfcc = librosa.feature.mfcc(S=spectrogram, n_mfcc=13)\n    mfcc = librosa.feature.delta(mfcc, order=2)\n    return spectrogram, mfcc\n\n\ndef show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n    librosa.display.specshow(mels, x_axis='time', y_axis='mel', \n                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n                            fmin=conf.fmin, fmax=conf.fmax)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.show()\n\n\ndef read_as_mels_mfcc(conf, pathname, trim_long_data, debug_display=False):\n    x = read_audio(conf, pathname, trim_long_data)\n    mels, mfcc = audio_to_mels_mfcc(conf, x)\n    if debug_display:\n        IPython.display.display(IPython.display.Audio(x, rate=conf.sampling_rate))\n        show_melspectrogram(conf, mels)\n    return mels, mfcc\n\n\nclass conf:\n    sampling_rate = 44100\n    duration = 3 # sec\n    duration_long = 5\n#     hop_length = 347*duration # to make time steps 128\n    fmin = 20\n    fmax = sampling_rate // 2\n    n_mels = 128\n    n_fft = n_mels * 20\n    padmode = 'constant'\n    samples = sampling_rate * duration\n    samples_long = sampling_rate * (duration_long)\n\n\ndef get_default_conf():\n    return conf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change the array to RBG scaler\ndef mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    # Stack X as [X,X,X]\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    X = X - mean\n    std = std or X.std()\n    Xstd = X / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    if (_max - _min) > eps:\n        # Normalize to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min) / (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        # Just zero\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V\n\ndef convert_wav_to_image(df, source):\n    X_mels = []\n    X_mfcc = []\n    for i, row in tqdm_notebook(df.iterrows()):\n        x_mels, x_mfcc = read_as_mels_mfcc(conf, source/str(row.fname), trim_long_data=True)\n        x_color = mono_to_color(x_mels)\n        X_mels.append(x_color)\n        X_mfcc.append(x_mfcc)\n    return X_mels, X_mfcc\n\n\ndef save_as_pkl_binary(obj, filename):\n    with open(filename, 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n\n\ndef load_pkl(filename):\n    with open(filename, 'rb') as f:\n        return pickle.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nconf = get_default_conf()\n\ndef convert_dataset(df, source_folder, mels_filename, mfcc_filename):\n    X_mels, X_mfcc = convert_wav_to_image(df, source=source_folder)\n    save_as_pkl_binary(X_mels, mels_filename)\n    save_as_pkl_binary(X_mfcc, mfcc_filename)\n    print(f'Created {mels_filename}')\n    print(f'Created {mfcc_filename}')\n    return X_mels, X_mfcc\n\nconvert_dataset(trn_curated_df, TRN_CURATED, MELS_TRN_CURATED, MFCC_TRN_CURATED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Best 50s"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = trn_noisy_df.copy()\ndf['singled'] = ~df.labels.str.contains(',')\nsingles_df = df[df.singled]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = singles_df.labels.unique()\nlabels, len(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxes_best50s = np.array([random.choices(singles_df[(singles_df.labels == l)].index, k=50)\n                          for l in labels]).ravel()\nbest50s_df = singles_df.loc[idxes_best50s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best50s_df.to_csv(CSV_TRN_NOISY_BEST50S, index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now best 50s are selected"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = convert_dataset(best50s_df, TRN_NOISY, MELS_TRN_NOISY_BEST50S, MFCC_TRN_NOISY_BEST50S)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}